#!/usr/bin/env python3
"""
çƒ­æ¦œæ•°æ®è·å–è„šæœ¬

ä½¿ç”¨ä»Šæ—¥çƒ­æ¦œ (rebang.today) çš„ jina.ai Reader API è·å–å®æ—¶çƒ­æ¦œæ•°æ®ã€‚

æ”¯æŒçš„å¹³å°ï¼š
- xhs: å°çº¢ä¹¦
- ne-news: ç½‘æ˜“æ–°é—»
- zhihu: çŸ¥ä¹
- weibo: å¾®åš
- douyin: æŠ–éŸ³
- bilibili: å“”å“©å“”å“©

ä½¿ç”¨æ–¹æ³•ï¼š
    python fetch_trending.py --platform xhs
    python fetch_trending.py --platform ne-news --limit 20
"""

import argparse
import json
import re
import sys
from datetime import datetime
from typing import List, Dict, Optional
from urllib.parse import unquote
import requests


# ä»Šæ—¥çƒ­æ¦œ jina.ai Reader API ç«¯ç‚¹
REBANG_API_BASE = "https://r.jina.ai/rebang.today"

# æ”¯æŒçš„å¹³å°æ˜ å°„
PLATFORMS = {
    "xhs": "xiaohongshu",      # å°çº¢ä¹¦
    "ne-news": "ne-news",      # ç½‘æ˜“æ–°é—»
    "zhihu": "zhihu",          # çŸ¥ä¹
    "weibo": "weibo",          # å¾®åš
    "douyin": "douyin",        # æŠ–éŸ³
    "bilibili": "bilibili",    # å“”å“©å“”å“©
    "36kr": "36kr",            # 36æ°ª
    "toutiao": "toutiao",      # ä»Šæ—¥å¤´æ¡
    "ithome": "ithome",        # ITä¹‹å®¶
}


def fetch_rebang(platform: str, limit: int = 50) -> List[Dict]:
    """
    ä»ä»Šæ—¥çƒ­æ¦œè·å–å¹³å°çƒ­æ¦œæ•°æ®

    Args:
        platform: å¹³å°ä»£ç  (xhs, ne-news, zhihuç­‰)
        limit: è¿”å›çš„æœ€å¤§æ•°é‡

    Returns:
        çƒ­æ¦œæ•°æ®åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«ï¼š
        - rank: æ’å
        - title: æ ‡é¢˜
        - heat: çƒ­åº¦å€¼
        - url: é“¾æ¥
        - trend: è¶‹åŠ¿ (hot/new/normal)
    """
    # è·å–å¹³å°å¯¹åº”çš„ tab å‚æ•°
    tab = PLATFORMS.get(platform)
    if not tab:
        print(f"âŒ é”™è¯¯ï¼šä¸æ”¯æŒçš„å¹³å° '{platform}'", file=sys.stderr)
        print(f"   æ”¯æŒçš„å¹³å°ï¼š{', '.join(PLATFORMS.keys())}", file=sys.stderr)
        return []

    # æ„å»º API URL
    url = f"{REBANG_API_BASE}/?tab={tab}"

    try:
        print(f"ğŸ“¡ æ­£åœ¨è·å– {platform} çƒ­æ¦œæ•°æ®...")
        response = requests.get(url, timeout=30)
        response.raise_for_status()

        # è§£æè¿”å›çš„å†…å®¹
        content = response.text

        # è§£æçƒ­æ¦œæ•°æ®
        trending_data = parse_rebang_content(content, platform, limit)

        print(f"ğŸ“Š è§£æåˆ° {len(trending_data)} æ¡æ•°æ®")

        return trending_data

    except requests.RequestException as e:
        print(f"âŒ è·å–çƒ­æ¦œæ•°æ®å¤±è´¥: {e}", file=sys.stderr)
        return []


def parse_rebang_content(content: str, platform: str, limit: int) -> List[Dict]:
    """
    è§£æä»Šæ—¥çƒ­æ¦œè¿”å›çš„ Markdown å†…å®¹

    å°çº¢ä¹¦æ ¼å¼ï¼š
    *   1
    [æ£‹åœ£è‚å«å¹³ç—…é€ æ–° ----------](https://www.xiaohongshu.com/search_result?keyword=... "æ£‹åœ£è‚å«å¹³ç—…é€")
    948.1w

    ç½‘æ˜“æ–°é—»æ ¼å¼ï¼š
    * [å›¾ç‰‡](url) [æ ‡é¢˜](url "title")æè¿°
    æ¥æº è·Ÿè´´æ•°

    Args:
        content: è¿”å›çš„æ–‡æœ¬å†…å®¹
        platform: å¹³å°ä»£ç 
        limit: æœ€å¤§è¿”å›æ•°é‡

    Returns:
        è§£æåçš„çƒ­æ¦œæ•°æ®åˆ—è¡¨
    """
    # æ ¹æ®å¹³å°é€‰æ‹©ä¸åŒçš„è§£ææ–¹å¼
    if platform == "ne-news":
        return parse_ne_news_format(content, limit)
    elif platform == "xhs":
        return parse_xhs_format(content, limit)
    else:
        # é»˜è®¤ä½¿ç”¨å°çº¢ä¹¦æ ¼å¼
        return parse_xhs_format(content, limit)


def parse_xhs_format(content: str, limit: int) -> List[Dict]:
    """
    è§£æå°çº¢ä¹¦æ ¼å¼çƒ­æ¦œ
    """
    trending_list = []

    # åŒ¹é…æ¨¡å¼ï¼š
    # *   æ•°å­—\n
    # [æ ‡é¢˜... æ ‡è®°](url "title")\n
    # çƒ­åº¦å€¼
    pattern = r'\*\s+(\d+)\s*\n\[([^\]]+)\]\(([^)]+)\)\s*\n\s*([\d.]+[wåƒä¸‡]?)'

    matches = re.findall(pattern, content)

    for match in matches:
        if len(trending_list) >= limit:
            break

        rank = int(match[0])
        title_with_flag = match[1]
        url = match[2]
        heat_str = match[3]

        # è§£ææ ‡é¢˜å’Œè¶‹åŠ¿æ ‡è®°
        title = title_with_flag.strip()

        # ç¡®å®šè¶‹åŠ¿
        trend = "normal"
        if " æ–° " in title or title.endswith(" æ–°"):
            trend = "new"
            title = re.sub(r'\s+æ–°\s*-+$', '', title)
            title = re.sub(r'\s+æ–°$', '', title)
        elif " çƒ­ " in title or title.endswith(" çƒ­"):
            trend = "hot"
            title = re.sub(r'\s+çƒ­\s*-+$', '', title)
            title = re.sub(r'\s+çƒ­$', '', title)

        # æ¸…ç†æ ‡é¢˜æœ«å°¾çš„æ¨ªçº¿
        title = re.sub(r'-+$', '', title).strip()

        # URLè§£ç ï¼ˆå¦‚æœéœ€è¦ï¼‰
        try:
            if 'keyword=' in url:
                keyword_match = re.search(r'keyword=([^&\s]+)', url)
                if keyword_match:
                    encoded_title = keyword_match.group(1)
                    decoded_title = unquote(encoded_title)
                    title = decoded_title
        except:
            pass

        # è§£æçƒ­åº¦å€¼
        heat = parse_heat_value(heat_str)

        trending_list.append({
            "rank": rank,
            "title": title,
            "url": url.strip(),
            "heat": heat,
            "trend": trend
        })

    return trending_list


def parse_ne_news_format(content: str, limit: int) -> List[Dict]:
    """
    è§£æç½‘æ˜“æ–°é—»æ ¼å¼çƒ­æ¦œ

    ç½‘æ˜“æ–°é—»æ ¼å¼è¾ƒå¤æ‚ï¼ŒåŒ…å«å›¾ç‰‡é“¾æ¥å’Œå¤šä¸ªè¡Œ
    ä½¿ç”¨ç®€åŒ–çš„è§£æé€»è¾‘ï¼šæå–æ‰€æœ‰æ–°é—»æ ‡é¢˜é“¾æ¥å’Œè·Ÿè´´æ•°
    """
    trending_list = []

    # æå–æ‰€æœ‰æ ‡é¢˜é“¾æ¥å’Œè·Ÿè´´æ•°
    # 1. æå–æ‰€æœ‰ [æ ‡é¢˜](url) æ¨¡å¼
    # 2. æå–æ‰€æœ‰ Xäººè·Ÿè´´ æ¨¡å¼
    # 3. é…å¯¹å®ƒä»¬

    title_pattern = r'\[([^\]]+)\]\((https://c\.m\.163\.com/news/a/[^\)]+)\)'
    comment_pattern = r'(\d+)äººè·Ÿè´´'

    titles = re.findall(title_pattern, content)
    comments = re.findall(comment_pattern, content)

    # é…å¯¹æ ‡é¢˜å’Œè·Ÿè´´æ•°ï¼ˆå‡è®¾å®ƒä»¬æ˜¯æŒ‰é¡ºåºå¯¹åº”çš„ï¼‰
    for i, (title, url) in enumerate(titles):
        if len(trending_list) >= limit:
            break

        # è·³è¿‡çº¯å›¾ç‰‡é“¾æ¥
        if 'Image' in title or len(title) < 5:
            continue

        # è·å–å¯¹åº”çš„è·Ÿè´´æ•°
        if i < len(comments):
            heat = int(comments[i])
        else:
            heat = 0

        # æ¸…ç†æ ‡é¢˜ä¸­çš„å¤šä½™æ¨ªçº¿
        title = re.sub(r'-+$', '', title).strip()

        trending_list.append({
            "rank": len(trending_list) + 1,
            "title": title,
            "url": url,
            "heat": heat,
            "trend": "normal"
        })

    return trending_list


def parse_heat_value(heat_str: str) -> Optional[int]:
    """
    è§£æçƒ­åº¦å­—ç¬¦ä¸²ä¸ºæ•°å€¼

    Args:
        heat_str: çƒ­åº¦å­—ç¬¦ä¸²ï¼Œå¦‚ "948.1w", "707.2w", "400w"

    Returns:
        çƒ­åº¦æ•°å€¼
    """
    if not heat_str:
        return None

    heat_str = heat_str.strip().lower()

    # å¤„ç† "w" (ä¸‡) å•ä½
    if 'w' in heat_str:
        try:
            value = float(heat_str.replace('w', ''))
            return int(value * 10000)
        except ValueError:
            pass

    # å¤„ç† "åƒä¸‡" å•ä½
    if 'åƒä¸‡' in heat_str:
        try:
            value = float(heat_str.replace('åƒä¸‡', ''))
            return int(value * 10000000)
        except ValueError:
            pass

    # çº¯æ•°å­—
    try:
        return int(float(heat_str))
    except ValueError:
        return None


def main():
    parser = argparse.ArgumentParser(
        description="è·å–å„å¹³å°å®æ—¶çƒ­æ¦œæ•°æ®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ”¯æŒçš„å¹³å°ï¼š
  xhs       å°çº¢ä¹¦
  ne-news   ç½‘æ˜“æ–°é—»
  zhihu     çŸ¥ä¹
  weibo     å¾®åš
  douyin    æŠ–éŸ³
  bilibili  å“”å“©å“”å“©
  36kr      36æ°ª
  toutiao   ä»Šæ—¥å¤´æ¡
  ithome    ITä¹‹å®¶

ç¤ºä¾‹ï¼š
  %(prog)s --platform xhs
  %(prog)s --platform ne-news --limit 20
  %(prog)s -p zhihu -o trending.json
        """
    )

    parser.add_argument(
        "--platform", "-p",
        required=True,
        choices=list(PLATFORMS.keys()),
        help="å¹³å°ä»£ç "
    )
    parser.add_argument(
        "--limit", "-l",
        type=int,
        default=50,
        help="è¿”å›çš„æœ€å¤§æ•°é‡ (é»˜è®¤: 50)"
    )
    parser.add_argument(
        "--output", "-o",
        help="è¾“å‡º JSON æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--pretty",
        action="store_true",
        help="ç¾åŒ–è¾“å‡ºæ ¼å¼"
    )

    args = parser.parse_args()

    # è·å–çƒ­æ¦œæ•°æ®
    trending_data = fetch_rebang(args.platform, args.limit)

    if not trending_data:
        print(f"âŒ æœªè·å–åˆ°çƒ­æ¦œæ•°æ®", file=sys.stderr)
        sys.exit(1)

    # æ„å»ºç»“æœ
    result = {
        "platform": args.platform,
        "platform_name": PLATFORMS[args.platform],
        "fetch_time": datetime.now().isoformat(),
        "count": len(trending_data),
        "data": trending_data
    }

    # è¾“å‡º
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2 if args.pretty else None)
        print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ° {args.output}")
        print(f"ğŸ“Š å…±è·å– {len(trending_data)} æ¡çƒ­æ¦œæ•°æ®")
    else:
        indent = 2 if args.pretty else None
        print(json.dumps(result, ensure_ascii=False, indent=indent))


if __name__ == "__main__":
    main()
